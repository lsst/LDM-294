\section{Lead institutions in \gls{DM} \label{sect:leadtutes}}

\subsection{LSST Tucson\label{sect:tucson}}

The \gls{LSST} Project Office in Tucson hosts the \gls{DM} \gls{Project Manager} (\secref{role:dmpm}) and the \gls{Systems Engineer} (\secref{role:sysengineer}).
In addition, it is home to the Science Quality and Reliability Engineering (\gls{SQuaRE}) group and \gls{LSST} International Communications and Base Site (\gls{ICBS}) groups, described below.

\subsubsection{Science Quality and Reliability Engineering \label{sect:square}}

The \gls{SQuaRE} group is primarily charged with providing technical feedback to the \gls{DM} \gls{Project Manager} that demonstrates that \gls{DM} is fulfilling its responsibilities with regard to quality — of both scientific data products and software — software performance, and reliability. As such, areas of activity include:

\begin{itemize}

\item Development of algorithms to detect and analyze quality issues with data\footnote{This may overlap with work carried out by the \gls{Science Pipelines} groups (\S\S\ref{sect:ap} \& \ref{sect:drp}). In some instances this will involve sharing code; in others, it may merit duplicating a \gls{metric} to ensure that it is correct.}

\item Infrastructure development to support the generation, collection, and analysis of data quality and performance metrics

\item \gls{DM} developer support services to ensure \gls{DM} is using appropriate tools to aid software quality

\item \gls{DM} documentation support, to include defining standards and providing tooling for documentation as well as some document writing

\item Support of publicly released software products, including porting and distributing them according to the scientific community's needs

\end{itemize}

In the event that \gls{SQuaRE} identifies issues with the performance or future maintainability of the \gls{DM} codebase, it will bring them to the attention of the \gls{DM} Software Architect. In the event that \gls{SQuaRE} identifies issues with the quality of the data or algorithmic performance, it will bring them to the attention of the \gls{DM} \gls{Subsystem Scientist}.

\subsubsection{LSST International Communications and Base Site}
The \gls{ICBS} group spans both Tucson and La Serena, and is responsible for the design, procurement, installation, deployment, verification, and operating support during construction and commissioning of all data communications networks at the \gls{Summit} and Base sites, as well as links between all the \gls{LSST} Sites, with two exceptions:  the \gls{Summit} Network (\gls{WBS} 1.04C.12.5) and the \gls{Archive} External Network (1.02C.07.04.06).  In the case of the exceptions, there are technical and managerial interfaces between the \gls{ICBS} and the responsible parties, as well as overlaps of staff.  The \gls{LSST} Network Engineering Team (\gls{NET}) spans all of these networking assignees and is chaired by the \gls{ICBS} staff.

The \gls{ICBS} group is also jointly responsible with the Data Facility Team at \gls{NCSA} for procurement, installation, deployment, verification, and operating support during construction and commissioning of the computing and storage infrastructure at the Base Site.

Since a large majority of the \gls{ICBS} work involves procurement and contracted services, the group works in close cooperation with \gls{AURA} procurement and contracts, as well as with the following major sub-awardees and their subcontractors:

\begin{itemize}
	\item \gls{REUNA}: Chilean National Networks
	\item Florida International University/AmLight: International Networks connecting Chile and the United States, and \gls{US} National Networks.
\end{itemize}

\subsection {Princeton University \label{sect:princeton}}

Princeton University hosts the Pipelines Scientist (\secref{role:pipe}) and the Data \gls{Release} Production group, described below.

\subsubsection{Data \gls{Release} Production \label{sect:drp}}

The Data \gls{Release} Production (\gls{DRP}) group has three major areas of activity within \gls{DM}.

\begin{itemize}

  \item{Definition and implementation of the scientific algorithms and pipelines which will be used to generate \gls{LSST}'s annual data releases;}

  \item{Definition and implementation of the algorithms and pipelines which will be used to produce the ``calibration products'' (for example, flat fields, characterization of detector effects, etc) which will be used as inputs to the photometric \gls{calibration} procedure in both nightly and annual data processing. This includes the development of the spectrophotometric data reduction \gls{pipeline} for the Auxiliary Telescope;}

  \item{Development, in conjunction with the \gls{Alert Production} team (\gls{AP}; \secref{sect:ap}), of a library of re-usable software libraries and components which form the basis of both the \gls{AP} and \gls{DRP} pipelines and which are made available to science users within the \gls{LSST} \gls{Science Platform}.}

\end{itemize}

Development of software in support of annual data releases and of reusable software components are carried out under the direction of the \gls{DRP} Science Lead, who acts as product owner for this part of the system.
The \gls{DRP} Science Lead is ultimately responsible to both the Pipelines Scientist (\secref{role:pipe}) and \gls{DM} \gls{Subsystem Scientist} (\secref{role:dmps}).

The product owner for the \gls{calibration} products is the \gls{LSST} \gls{Calibration Scientist} (who doubles as the Pipelines Scientist, \secref{role:pipe}).
The \gls{Calibration Scientist} liaises with other \gls{LSST} subsystems and with the products owners of the annual and nightly data processing pipelines to ensure that appropriate \gls{calibration} products are available to those pipelines to enable them to meet specifications.

Management of the group is the responsibility of the Deputy \gls{Science Pipelines} \gls{T/CAM}, reporting to the \gls{Science Pipelines} \gls{T/CAM} and ultimately to the \gls{DM} \gls{Project Manager} (\secref{role:dmpm}).

The \gls{DRP} group is responsible for delivering software which adheres to the architectural and testing standard defined by the Software Architect (\secref{role:softarc}).
In addition, the \gls{DRP} group is responsible for testing each major product delivered to demonstrate its fitness for purpose, and working with the \gls{DM} \gls{Subsystem Scientist} and \gls{DM} System Science Team (\secref{sect:dmsst}) to define, run and analyze ``data challenges'' and other large scale tests to validate the performance of the data release production system.

\subsection {The University of Washington\label{sect:uw}}

\subsubsection{Alert Production\label{sect:ap}}

The \gls{Alert Production} (\gls{AP}) group has 4 major areas of activity within \gls{DM}.

\begin{itemize}

  \item{Definition and implementation of the scientific algorithms and pipelines which will be used to generate alerts from \gls{LSST}'s image stream.  This will serve as the alert generation \gls{pipeline};}

  \item{Definition and implementation a scalable and reliable system for transmitting the alerts generated by the alert generation \gls{pipeline} including a mechanism for applying simple filters to the stream. This is the alert distribution and filtering system;}

  \item{Definition and implementation of a system for identifying moving objects in our solar system and fitting their physical properties. This is the Moving Objects Processing System (\gls{MOPS});}

  \item{Development, in conjunction with the Data \gls{Release} Production team (\gls{DRP}; \secref{sect:drp}), of a library of re-usable software libraries and components which form the basis of both the \gls{AP} and \gls{DRP} pipelines and which are made available to science users within the \gls{LSST} \gls{Science Platform}.}

\end{itemize}

Development of software in support of the alert generation \gls{pipeline}, alert distribution system, \gls{MOPS} and of reusable software components are carried out under the direction of the \gls{AP} Science Lead, who acts as product owner for this part of the system.
The \gls{AP} Science Lead is ultimately responsible to both the Pipelines Scientist (\secref{role:pipe}) and \gls{DM} \gls{Subsystem Scientist} (\secref{role:dmps}).

Management of the group is the responsibility of the \gls{Science Pipelines} \gls{T/CAM}, reporting to the \gls{DM} \gls{Project Manager} (\secref{role:dmpm}).

The \gls{AP} group is responsible for delivering software which adheres to the architectural and testing standard defined by the Software Architect (\secref{role:softarc}).
In addition, the \gls{AP} group is responsible for testing each major product delivered to demonstrate its fitness for purpose, and working with the \gls{DM} \gls{Subsystem Scientist} and \gls{DM} System Science Team (\secref{sect:dmsst}) to define, run and analyze ``data challenges'' and other large scale tests to validate the performance of the data release production system.

\subsection {California Institute of Technology/IPAC\label{sect:ipac}}
IPAC hosts the \gls{LSST} \gls{Science Platform} Scientist (\secref{role:scip}), the \gls{DM} Interface Scientist (\secref{role:dmis}), and the Science User Interface and Tools (\gls{SUIT}) group described below.

\subsubsection{ Science User Interface and Tools}

The Science User Interface and Tools (\gls{SUIT}) group has four major areas of activity within \gls{DM}:

Design and develop the \gls{Firefly} Web-based visualization and data exploration framework, based upon the the same software already in operations in other \gls{NASA} archive services (i.e. \gls{IRSA}’s \gls{WISE} Image Service) . The \gls{Firefly} framework provides three basic components –  image display and manipulation, tabular table display and manipulation, and \gls{2D} plotting – all of which work together to provide different views into the same data. \gls{Firefly} also provides JavaScript and Python APIs to enable developers to easily use the components in their own Web pages or Jupyter notebooks.

Develop the interfaces needed to connect Firefly to the other LSST Science Platform components, e.g., connect to authentication and authorization, DAX services, user workspace, flexible compute system.  Develop visualizations of the objects in the LSST Data Products data model, and support their metadata; e.g., Footprint, HeavyFootprint, WCS models.  Provide basic access to Firefly from the LSST stack via afw.display.

Design and implement the Portal Aspect of the \gls{LSST} \gls{Science Platform} for \gls{Data Access Center}, based on \gls{Firefly}, providing scientists an easy to use interface to search, visualize, and explore \gls{LSST} data. The portal will enable users to do as much data discovery and exploration as possible through complex searches and facilitate data assessment through visualization and interaction.  The Portal will assist users in understanding the semantic linkages between the various \gls{LSST} data products. The Portal will guide users to documentation on the \gls{Science Platform} itself, the \gls{LSST} data products, and the processing that generated them.  Support linkage between the Portal and Notebook aspects of the \gls{Science Platform}, enabling users to switch between the aspects easily by providing tools to make data selected in the Portal readily available for further analysis in user notebooks.

Design and develop the \gls{LSST} \gls{Alert} Subscription web portal to enable scientists to access the alert system. The subscription service will enable users to register filters and destinations for alerts matching their interests. The \gls{Alert} portal will also provide basic capabilities for searching alerts history and for exploring linkage between alerts and other data products.




\subsection {SLAC\label{sect:slac}}
SLAC hosts the \gls{DM} Software Architect (\secref{role:softarc}) and the Science Data \gls{Archive} and Data Access
Services group described below.

\subsubsection{Science Data \gls{Archive} and Data Access Services \label{sect:dax}}

The Science Data \gls{Archive} and Data Access Services (\gls{DAX}) group has the following major areas of activity
within \gls{DM}:

\begin{itemize}

  \item{Provides software to support ingestion, indexing, query, and administration of \gls{DM} catalog and image
  data products, data \gls{provenance}, and other associated \gls{metadata} within the \gls{LSST} Data Access Centers;}

  \item{Provides implementations of data access services (including \gls{IVOA} services), as well as associated
  client libraries, to be hosted within the \gls{LSST} Data Access Centers, which facilitate interaction between
  \gls{LSST} data products and tools provided by both other parts of the \gls{LSST} project and by the astronomical
  research community at large;}

  \item{Provides a Python framework (the ``Data \gls{Butler}''), used by the \gls{LSST} science pipelines, to facilitate
  abstract persistence/retrieval of in-memory Python objects to/from generic archives of those objects;}

  \item{Provides a Python framework (``SuperTask'') which serves as an interface layer between \gls{pipeline}
  orchestration and algorithmic code, and which allows pipelines to be constructed, configured, and run at
  the level of a single node or a group of tightly-synchronized nodes;}

  \item{Provides support for various middleware and infrastructure toolkits used by \gls{DM} which would otherwise
  have no authoritative home institution within DM (e.g. logging support library, spherical geometry support
  library).}

\end{itemize}

Management of the group is the responsibility of the \gls{DAX} \gls{T/CAM}, reporting to the \gls{DM} \gls{Project Manager}
(\secref{role:dmpm}).

The \gls{DAX} group is responsible for delivering software which adheres to the architectural and testing standard
defined by the Software Architect (\secref{role:softarc}). In addition, the \gls{DAX} group is responsible for
testing each major product delivered to demonstrate its fitness for purpose, and running and analyzing large
scale tests to validate the performance of the science data archive and data access systems.

\subsection {NCSA\label{sect:ncsa}}


NCSA hosts the \gls{LSST} Project Office Information Security Officer and Computer Security group, as well as the \gls{DM} group responsible for construction and integration of the \gls{LSST} Data Facility (\gls{LDF}), described below.

The \gls{LDF} group has the following major areas of activity within \gls{DM}:

\begin{enumerate}
	\item	\gls{Construction} of services, including software and operational methods, supporting observatory operations and nightly data production (Level 1 Services). Level 1 Services ingest raw data from all Observatory cameras and the Engineering and Facilities Database (\gls{EFD}) into the central archive; provide a dedicated computing service controllable by the Observatory Control System (\gls{OCS}) for prompt generation of nightly \gls{calibration} assessments, science image parameters, and \gls{transient} alerts; and provide computing services, data access, and a \gls{QA} portal for Observatory staff.
	\item	\gls{Construction} of services, including software and operational methods, for bulk batch data production. \gls{Batch Production} Services execute processing campaigns, using resources at \gls{NCSA} and satellite computing centers, to produce data release products, generate templates and calibrations, and perform scaled testing of science pipelines to assess production readiness.
	\item	\gls{Construction} of services, including software and operational methods, for hosting and operating data access services for community users. These services host the \gls{SUIT} portal, manage the JupyterLab environment, provide computing and data storage for the Data Access Centers, enable bulk data export, and host the \gls{LSST} limited alert-filtering service and feeds to community-provided brokers.
	\item	\gls{Construction} of services, including software and operational methods, for the \gls{Data Backbone}. \gls{Data Backbone} Services provide ingestion, management, distribution, access, integrity checking, and backup and disaster recovery for files and catalog data in the \gls{LSST} central data archive.
	\item	\gls{Construction} and operation of services for \gls{LSST} staff. Staff Services provide specific testing and integration platforms (e.g., a Prototype \gls{Data Access Center}) and general computing and data services for \gls{LSST} developers.
	\item	Provisioning and management of hardware infrastructure at NCSA and the Chilean Base Center for all services described above, as well as infrastructure for project-wide network-based computer security services and authentication and authorization services.
	\item	\gls{Construction} and operation of a service management framework and methods to monitor operations of service elements in accordance with service level agreements, track issues, manage service availability, and support change management.
	\item	Operation of services and \gls{IT} systems during construction to support on-going development, integration, and commissioning activities.
\end{enumerate}
The \gls{LDF} group is responsible for delivering instantiated production services, which integrate software and hardware components developed across \gls{DM}. The \gls{LDF} group performs large-scale tests to integrate and verify production readiness of all components.
